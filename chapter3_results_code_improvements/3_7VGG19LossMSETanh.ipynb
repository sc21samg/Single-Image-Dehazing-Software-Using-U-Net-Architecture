{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiTwCCziPWwX",
        "outputId": "13771a02-763e-467a-9315-6fea2c70ca85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 256, 256, 64)         1792      ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_38[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_36[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 256, 256, 64)         256       ['conv2d_39[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_37 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 64)                   0         ['activation_37[0][0]']       \n",
            " 8 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_18 (Reshape)        (None, 1, 1, 64)             0         ['global_average_pooling2d_18[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_36 (Dense)            (None, 1, 1, 4)              256       ['reshape_18[0][0]']          \n",
            "                                                                                                  \n",
            " dense_37 (Dense)            (None, 1, 1, 64)             256       ['dense_36[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_18 (Multiply)      (None, 256, 256, 64)         0         ['activation_37[0][0]',       \n",
            "                                                                     'dense_37[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPoolin  (None, 128, 128, 64)         0         ['multiply_18[0][0]']         \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_8[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 128, 128, 128)        512       ['conv2d_40[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_38 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_38[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 128, 128, 128)        512       ['conv2d_41[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_39 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 128)                  0         ['activation_39[0][0]']       \n",
            " 9 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_19 (Reshape)        (None, 1, 1, 128)            0         ['global_average_pooling2d_19[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_38 (Dense)            (None, 1, 1, 8)              1024      ['reshape_19[0][0]']          \n",
            "                                                                                                  \n",
            " dense_39 (Dense)            (None, 1, 1, 128)            1024      ['dense_38[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_19 (Multiply)      (None, 128, 128, 128)        0         ['activation_39[0][0]',       \n",
            "                                                                     'dense_39[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPoolin  (None, 64, 64, 128)          0         ['multiply_19[0][0]']         \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 64, 64, 256)          1024      ['conv2d_42[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_40 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_40[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 64, 64, 256)          1024      ['conv2d_43[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_41 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 256)                  0         ['activation_41[0][0]']       \n",
            " 0 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_20 (Reshape)        (None, 1, 1, 256)            0         ['global_average_pooling2d_20[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_40 (Dense)            (None, 1, 1, 16)             4096      ['reshape_20[0][0]']          \n",
            "                                                                                                  \n",
            " dense_41 (Dense)            (None, 1, 1, 256)            4096      ['dense_40[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_20 (Multiply)      (None, 64, 64, 256)          0         ['activation_41[0][0]',       \n",
            "                                                                     'dense_41[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooli  (None, 32, 32, 256)          0         ['multiply_20[0][0]']         \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 32, 32, 512)          2048      ['conv2d_44[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_42 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_42[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 32, 32, 512)          2048      ['conv2d_45[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_43 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 512)                  0         ['activation_43[0][0]']       \n",
            " 1 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_21 (Reshape)        (None, 1, 1, 512)            0         ['global_average_pooling2d_21[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_42 (Dense)            (None, 1, 1, 32)             16384     ['reshape_21[0][0]']          \n",
            "                                                                                                  \n",
            " dense_43 (Dense)            (None, 1, 1, 512)            16384     ['dense_42[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_21 (Multiply)      (None, 32, 32, 512)          0         ['activation_43[0][0]',       \n",
            "                                                                     'dense_43[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 32, 32, 512)          0         ['multiply_21[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooli  (None, 16, 16, 512)          0         ['dropout_4[0][0]']           \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_46[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_44 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_44[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_47[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_45 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 1024)                 0         ['activation_45[0][0]']       \n",
            " 2 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_22 (Reshape)        (None, 1, 1, 1024)           0         ['global_average_pooling2d_22[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_44 (Dense)            (None, 1, 1, 64)             65536     ['reshape_22[0][0]']          \n",
            "                                                                                                  \n",
            " dense_45 (Dense)            (None, 1, 1, 1024)           65536     ['dense_44[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_22 (Multiply)      (None, 16, 16, 1024)         0         ['activation_45[0][0]',       \n",
            "                                                                     'dense_45[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 16, 16, 1024)         0         ['multiply_22[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_8 (Conv2D  (None, 32, 32, 512)          2097664   ['dropout_5[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate  (None, 32, 32, 1024)         0         ['conv2d_transpose_8[0][0]',  \n",
            " )                                                                   'multiply_21[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)          (None, 32, 32, 512)          4719104   ['concatenate_8[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_46 (Ba  (None, 32, 32, 512)          2048      ['conv2d_48[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_46 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_46[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_47 (Ba  (None, 32, 32, 512)          2048      ['conv2d_49[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_47 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_47[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 512)                  0         ['activation_47[0][0]']       \n",
            " 3 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_23 (Reshape)        (None, 1, 1, 512)            0         ['global_average_pooling2d_23[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_46 (Dense)            (None, 1, 1, 32)             16384     ['reshape_23[0][0]']          \n",
            "                                                                                                  \n",
            " dense_47 (Dense)            (None, 1, 1, 512)            16384     ['dense_46[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_23 (Multiply)      (None, 32, 32, 512)          0         ['activation_47[0][0]',       \n",
            "                                                                     'dense_47[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_9 (Conv2D  (None, 64, 64, 256)          524544    ['multiply_23[0][0]']         \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate  (None, 64, 64, 512)          0         ['conv2d_transpose_9[0][0]',  \n",
            " )                                                                   'multiply_20[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)          (None, 64, 64, 256)          1179904   ['concatenate_9[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_48 (Ba  (None, 64, 64, 256)          1024      ['conv2d_50[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_48 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_48[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_49 (Ba  (None, 64, 64, 256)          1024      ['conv2d_51[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_49 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 256)                  0         ['activation_49[0][0]']       \n",
            " 4 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_24 (Reshape)        (None, 1, 1, 256)            0         ['global_average_pooling2d_24[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_48 (Dense)            (None, 1, 1, 16)             4096      ['reshape_24[0][0]']          \n",
            "                                                                                                  \n",
            " dense_49 (Dense)            (None, 1, 1, 256)            4096      ['dense_48[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_24 (Multiply)      (None, 64, 64, 256)          0         ['activation_49[0][0]',       \n",
            "                                                                     'dense_49[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_10 (Conv2  (None, 128, 128, 128)        131200    ['multiply_24[0][0]']         \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenat  (None, 128, 128, 256)        0         ['conv2d_transpose_10[0][0]', \n",
            " e)                                                                  'multiply_19[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)          (None, 128, 128, 128)        295040    ['concatenate_10[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_50 (Ba  (None, 128, 128, 128)        512       ['conv2d_52[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_50 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_50[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_51 (Ba  (None, 128, 128, 128)        512       ['conv2d_53[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_51 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 128)                  0         ['activation_51[0][0]']       \n",
            " 5 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_25 (Reshape)        (None, 1, 1, 128)            0         ['global_average_pooling2d_25[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_50 (Dense)            (None, 1, 1, 8)              1024      ['reshape_25[0][0]']          \n",
            "                                                                                                  \n",
            " dense_51 (Dense)            (None, 1, 1, 128)            1024      ['dense_50[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_25 (Multiply)      (None, 128, 128, 128)        0         ['activation_51[0][0]',       \n",
            "                                                                     'dense_51[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_11 (Conv2  (None, 256, 256, 64)         32832     ['multiply_25[0][0]']         \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenat  (None, 256, 256, 128)        0         ['conv2d_transpose_11[0][0]', \n",
            " e)                                                                  'multiply_18[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)          (None, 256, 256, 64)         73792     ['concatenate_11[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_52 (Ba  (None, 256, 256, 64)         256       ['conv2d_54[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_52 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_52[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_53 (Ba  (None, 256, 256, 64)         256       ['conv2d_55[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_53 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_53[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 64)                   0         ['activation_53[0][0]']       \n",
            " 6 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_26 (Reshape)        (None, 1, 1, 64)             0         ['global_average_pooling2d_26[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_52 (Dense)            (None, 1, 1, 4)              256       ['reshape_26[0][0]']          \n",
            "                                                                                                  \n",
            " dense_53 (Dense)            (None, 1, 1, 64)             256       ['dense_52[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_26 (Multiply)      (None, 256, 256, 64)         0         ['activation_53[0][0]',       \n",
            "                                                                     'dense_53[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)          (None, 256, 256, 3)          195       ['multiply_26[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31273539 (119.30 MB)\n",
            "Trainable params: 31261763 (119.25 MB)\n",
            "Non-trainable params: 11776 (46.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Conv2DTranspose, Concatenate, Activation,\n",
        "                                     BatchNormalization, GlobalAveragePooling2D, Reshape, Dense, multiply,\n",
        "                                     Dropout)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.losses import MSE, MeanSquaredError\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "\n",
        "# Load VGG19 model for perceptual loss, excluding the top fully connected layers\n",
        "vgg = VGG19(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n",
        "vgg.trainable = False\n",
        "\n",
        "# Select the output layer for feature extraction\n",
        "output_layer = vgg.get_layer('block2_conv2').output\n",
        "vgg_model = Model(inputs=vgg.input, outputs=output_layer)\n",
        "\n",
        "def perceptual_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates the perceptual loss between y_true and y_pred using the VGG19 model.\n",
        "    \"\"\"\n",
        "    vgg_true = vgg_model(y_true)\n",
        "    vgg_pred = vgg_model(y_pred)\n",
        "    return K.mean(K.square(vgg_true - vgg_pred))\n",
        "\n",
        "\n",
        "# Initialize Mean Squared Error loss instance\n",
        "mse_loss = MeanSquaredError()\n",
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Custom loss function that combines MSE and perceptual loss,\n",
        "    with explicit type casting for mixed precision compatibility.\n",
        "    \"\"\"\n",
        "    mse = mse_loss(y_true, y_pred)\n",
        "    p_loss = perceptual_loss(y_true, y_pred)\n",
        "\n",
        "    # Ensure both mse and p_loss are float32 before addition\n",
        "    mse = tf.cast(mse, 'float32')\n",
        "    p_loss = tf.cast(p_loss, 'float32')\n",
        "\n",
        "    return mse + p_loss\n",
        "\n",
        "\n",
        "# Squeeze and Excite block\n",
        "def squeeze_excite_block(input_tensor, ratio=16):\n",
        "    init = input_tensor\n",
        "    channel_axis = -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "\n",
        "    x = multiply([init, se])\n",
        "    return x\n",
        "\n",
        "# Define a convolutional block\n",
        "def conv_block(x, num_filters):\n",
        "    x = Conv2D(num_filters, (3, 3), padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(num_filters, (3, 3), padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "# Build U-Net model incorporating Squeeze and Excite blocks and adding Bottleneck with Dropout\n",
        "def build_unet(input_size=(256, 256, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Contracting Path (Encoder)\n",
        "    c1 = conv_block(inputs, 64)\n",
        "    c1 = squeeze_excite_block(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = conv_block(p1, 128)\n",
        "    c2 = squeeze_excite_block(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = conv_block(p2, 256)\n",
        "    c3 = squeeze_excite_block(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = conv_block(p3, 512)\n",
        "    c4 = squeeze_excite_block(c4)\n",
        "    d4 = Dropout(0.5)(c4)\n",
        "    p4 = MaxPooling2D((2, 2))(d4)\n",
        "\n",
        "    # Bottleneck with dropout\n",
        "    c5 = conv_block(p4, 1024)\n",
        "    c5 = squeeze_excite_block(c5)\n",
        "    c5 = Dropout(0.5)(c5)  # Adding dropout in the bottleneck\n",
        "\n",
        "    # Expansive Path (Decoder)\n",
        "    u4 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u4 = Concatenate()([u4, c4])\n",
        "    c6 = conv_block(u4, 512)\n",
        "    c6 = squeeze_excite_block(c6)\n",
        "\n",
        "    u3 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u3 = Concatenate()([u3, c3])\n",
        "    c7 = conv_block(u3, 256)\n",
        "    c7 = squeeze_excite_block(c7)\n",
        "\n",
        "    u2 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u2 = Concatenate()([u2, c2])\n",
        "    c8 = conv_block(u2, 128)\n",
        "    c8 = squeeze_excite_block(c8)\n",
        "\n",
        "    u1 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u1 = Concatenate()([u1, c1])\n",
        "    c9 = conv_block(u1, 64)\n",
        "    c9 = squeeze_excite_block(c9)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Conv2D(3, (1, 1), activation='tanh')(c9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Metrics\n",
        "def psnr_metric(y_true, y_pred):\n",
        "    # Peak Signal-to-Noise Ratio metric\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=1.0)\n",
        "\n",
        "def ssim_metric(y_true, y_pred):\n",
        "    # Structural Similarity Index\n",
        "    y_true_f32 = tf.cast(y_true, tf.float32)\n",
        "    y_pred_f32 = tf.cast(y_pred, tf.float32)\n",
        "    return tf.image.ssim(y_true_f32, y_pred_f32, max_val=1.0)\n",
        "\n",
        "# Example usage\n",
        "model = build_unet((256, 256, 3))\n",
        "model.compile(optimizer='adam', loss=custom_loss, metrics=[psnr_metric, ssim_metric])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhv6DYPHtTwe",
        "outputId": "9d4ccf7d-f852-44d3-a78e-83240d716b55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Starting dataset creation...\n",
            "Collecting image paths...\n",
            "Collected 2949 pairs of images.\n",
            "Creating dataset from paths...\n",
            "Processing: Tensor(\"args_0:0\", shape=(), dtype=string) and Tensor(\"args_1:0\", shape=(), dtype=string)\n",
            "Shuffling dataset...\n",
            "Batching dataset...\n",
            "Dataset created and ready for use.\n",
            "Sample batch - Hazy images shape: (32, 256, 256, 3), dtype: <dtype: 'float32'>\n",
            "Sample batch - Clear images shape: (32, 256, 256, 3), dtype: <dtype: 'float32'>\n",
            "Starting Epoch 1\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 16s 457ms/step - loss: 10.8954 - psnr_metric: 5.8991 - ssim_metric: -0.0224 - val_loss: 3.7506 - val_psnr_metric: 9.4138 - val_ssim_metric: 0.1009\n",
            "Starting Epoch 2\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 6.6287 - psnr_metric: 6.3731 - ssim_metric: -0.0418 - val_loss: 3.5338 - val_psnr_metric: 9.7473 - val_ssim_metric: 0.1033\n",
            "Starting Epoch 3\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 4.7767 - psnr_metric: 6.7288 - ssim_metric: -0.0480 - val_loss: 3.4035 - val_psnr_metric: 9.8607 - val_ssim_metric: 0.0826\n",
            "Starting Epoch 4\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 3.7216 - psnr_metric: 6.9412 - ssim_metric: -0.0567 - val_loss: 3.3102 - val_psnr_metric: 9.8798 - val_ssim_metric: 0.0648\n",
            "Starting Epoch 5\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 3.1234 - psnr_metric: 7.2007 - ssim_metric: -0.0617 - val_loss: 3.2515 - val_psnr_metric: 9.8034 - val_ssim_metric: 0.0454\n",
            "Starting Epoch 6\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 2.8014 - psnr_metric: 7.4308 - ssim_metric: -0.0548 - val_loss: 3.2283 - val_psnr_metric: 9.6849 - val_ssim_metric: 0.0231\n",
            "Starting Epoch 7\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 2.5062 - psnr_metric: 7.6586 - ssim_metric: -0.0627 - val_loss: 3.2370 - val_psnr_metric: 9.5183 - val_ssim_metric: -0.0017\n",
            "Starting Epoch 8\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 2.3614 - psnr_metric: 7.8315 - ssim_metric: -0.0606 - val_loss: 3.2476 - val_psnr_metric: 9.3971 - val_ssim_metric: -0.0186\n",
            "Starting Epoch 9\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 2.2000 - psnr_metric: 8.0509 - ssim_metric: -0.0570 - val_loss: 3.2415 - val_psnr_metric: 9.3732 - val_ssim_metric: -0.0207\n",
            "Starting Epoch 10\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 2.0539 - psnr_metric: 8.2364 - ssim_metric: -0.0553 - val_loss: 3.2117 - val_psnr_metric: 9.4083 - val_ssim_metric: -0.0165\n",
            "Starting Epoch 11\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.9309 - psnr_metric: 8.5100 - ssim_metric: -0.0501 - val_loss: 3.1716 - val_psnr_metric: 9.4575 - val_ssim_metric: -0.0107\n",
            "Starting Epoch 12\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.7885 - psnr_metric: 8.6860 - ssim_metric: -0.0551 - val_loss: 3.1405 - val_psnr_metric: 9.4831 - val_ssim_metric: -0.0062\n",
            "Starting Epoch 13\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.6957 - psnr_metric: 8.8714 - ssim_metric: -0.0413 - val_loss: 3.1349 - val_psnr_metric: 9.4552 - val_ssim_metric: -0.0051\n",
            "Starting Epoch 14\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.5850 - psnr_metric: 9.1712 - ssim_metric: -0.0329 - val_loss: 3.1113 - val_psnr_metric: 9.4757 - val_ssim_metric: 4.4245e-04\n",
            "Starting Epoch 15\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.5233 - psnr_metric: 9.2903 - ssim_metric: -0.0145 - val_loss: 3.0885 - val_psnr_metric: 9.5192 - val_ssim_metric: 0.0087\n",
            "Starting Epoch 16\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.4787 - psnr_metric: 9.3596 - ssim_metric: -0.0152 - val_loss: 3.0553 - val_psnr_metric: 9.5831 - val_ssim_metric: 0.0178\n",
            "Starting Epoch 17\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.3461 - psnr_metric: 9.5922 - ssim_metric: 6.5634e-04 - val_loss: 3.0155 - val_psnr_metric: 9.6553 - val_ssim_metric: 0.0273\n",
            "Starting Epoch 18\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.2501 - psnr_metric: 9.9054 - ssim_metric: 0.0164 - val_loss: 2.9521 - val_psnr_metric: 9.7425 - val_ssim_metric: 0.0377\n",
            "Starting Epoch 19\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.2093 - psnr_metric: 10.0071 - ssim_metric: 0.0253 - val_loss: 2.8872 - val_psnr_metric: 9.8427 - val_ssim_metric: 0.0500\n",
            "Starting Epoch 20\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.1754 - psnr_metric: 10.0450 - ssim_metric: 0.0335 - val_loss: 2.8457 - val_psnr_metric: 9.9110 - val_ssim_metric: 0.0594\n",
            "Starting Epoch 21\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.1327 - psnr_metric: 10.3332 - ssim_metric: 0.0567 - val_loss: 2.7852 - val_psnr_metric: 10.0141 - val_ssim_metric: 0.0698\n",
            "Starting Epoch 22\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.1103 - psnr_metric: 10.2849 - ssim_metric: 0.0592 - val_loss: 2.7443 - val_psnr_metric: 10.0826 - val_ssim_metric: 0.0792\n",
            "Starting Epoch 23\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 1.0802 - psnr_metric: 10.2958 - ssim_metric: 0.0607 - val_loss: 2.7315 - val_psnr_metric: 10.0945 - val_ssim_metric: 0.0845\n",
            "Starting Epoch 24\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.0145 - psnr_metric: 10.5513 - ssim_metric: 0.0808 - val_loss: 2.6989 - val_psnr_metric: 10.1450 - val_ssim_metric: 0.0931\n",
            "Starting Epoch 25\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.0241 - psnr_metric: 10.5750 - ssim_metric: 0.0896 - val_loss: 2.6586 - val_psnr_metric: 10.2020 - val_ssim_metric: 0.1009\n",
            "Starting Epoch 26\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 0.9945 - psnr_metric: 10.6986 - ssim_metric: 0.0981 - val_loss: 2.6253 - val_psnr_metric: 10.2750 - val_ssim_metric: 0.1109\n",
            "Starting Epoch 27\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 1.0135 - psnr_metric: 10.5306 - ssim_metric: 0.0941 - val_loss: 2.5698 - val_psnr_metric: 10.3607 - val_ssim_metric: 0.1206\n",
            "Starting Epoch 28\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 0.9790 - psnr_metric: 10.6326 - ssim_metric: 0.1020 - val_loss: 2.4640 - val_psnr_metric: 10.5435 - val_ssim_metric: 0.1365\n",
            "Starting Epoch 29\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 0.9662 - psnr_metric: 10.8068 - ssim_metric: 0.1143 - val_loss: 2.4444 - val_psnr_metric: 10.5778 - val_ssim_metric: 0.1421\n",
            "Starting Epoch 30\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 0.9353 - psnr_metric: 10.8624 - ssim_metric: 0.1249 - val_loss: 2.4824 - val_psnr_metric: 10.4988 - val_ssim_metric: 0.1413\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.4824 - psnr_metric: 10.4988 - ssim_metric: 0.1413\n",
            "Validation Loss: 2.482445001602173, Validation PSNR: 10.498847007751465, Validation SSIM: 0.14129656553268433\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "def decode_img(img, image_size=(256, 256)):\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, image_size)\n",
        "    img /= 255.0  # Normalize to [0,1]\n",
        "    return img\n",
        "\n",
        "def process_path(clear_path, hazy_path):\n",
        "    print(f\"Processing: {clear_path} and {hazy_path}\")  # Print the paths being processed\n",
        "    clear_img = tf.io.read_file(clear_path)\n",
        "    clear_img = decode_img(clear_img)\n",
        "    hazy_img = tf.io.read_file(hazy_path)\n",
        "    hazy_img = decode_img(hazy_img)\n",
        "    return hazy_img, clear_img\n",
        "\n",
        "def create_dataset(dir_pairs, image_size=(256, 256), batch_size=32, shuffle=True):\n",
        "    clear_paths, hazy_paths = [], []\n",
        "\n",
        "    print(\"Collecting image paths...\")\n",
        "    for clear_dir, hazy_dir in dir_pairs:\n",
        "        # Check if directories exist\n",
        "        if not os.path.exists(clear_dir):\n",
        "            print(f\"Directory does not exist: {clear_dir}\")\n",
        "            continue\n",
        "        if not os.path.exists(hazy_dir):\n",
        "            print(f\"Directory does not exist: {hazy_dir}\")\n",
        "            continue\n",
        "\n",
        "        for file_name in sorted(os.listdir(clear_dir)):\n",
        "            if not file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                continue\n",
        "\n",
        "            base_name = file_name.rsplit('.', 1)[0]\n",
        "            pattern = f\"{base_name}_*\"\n",
        "            hazy_files = [f for f in os.listdir(hazy_dir) if f.startswith(pattern) and f.lower().endswith('.png')]\n",
        "\n",
        "            for hazy_file in hazy_files:\n",
        "                clear_paths.append(os.path.join(clear_dir, file_name))\n",
        "                hazy_paths.append(os.path.join(hazy_dir, hazy_file))\n",
        "\n",
        "    if not clear_paths:\n",
        "        print(\"No image pairs were collected.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def create_dataset(dir_pairs, image_size=(256, 256), batch_size=32, shuffle=True):\n",
        "    clear_paths, hazy_paths = [], []\n",
        "\n",
        "    print(\"Collecting image paths...\")\n",
        "    for clear_dir, hazy_dir in dir_pairs:\n",
        "        if not os.path.exists(clear_dir) or not os.path.exists(hazy_dir):\n",
        "            print(f\"Directory not found: {clear_dir} or {hazy_dir}\")\n",
        "            continue\n",
        "\n",
        "        clear_files = os.listdir(clear_dir)\n",
        "        hazy_files = os.listdir(hazy_dir)\n",
        "\n",
        "        if not clear_files or not hazy_files:\n",
        "            print(f\"No files found in directories: {clear_dir} or {hazy_dir}\")\n",
        "            continue\n",
        "\n",
        "        for file_name in sorted(clear_files):\n",
        "            if not file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                continue\n",
        "\n",
        "            base_name = file_name.split('.')[0]\n",
        "            matched_hazy_files = [f for f in hazy_files if f.startswith(base_name + \"_\") and f.lower().endswith('.png')]\n",
        "\n",
        "            if not matched_hazy_files:\n",
        "                print(f\"No hazy images matched for {file_name}\")\n",
        "                continue\n",
        "\n",
        "            for hazy_file in matched_hazy_files:\n",
        "                clear_paths.append(os.path.join(clear_dir, file_name))\n",
        "                hazy_paths.append(os.path.join(hazy_dir, hazy_file))\n",
        "    if not clear_paths:\n",
        "        print(\"No image pairs were collected.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Collected {len(clear_paths)} pairs of images.\")\n",
        "\n",
        "    # Create a tf.data.Dataset from paths\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((clear_paths, hazy_paths))\n",
        "    print(\"Creating dataset from paths...\")\n",
        "    dataset = dataset.map(lambda x, y: process_path(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if shuffle:\n",
        "        print(\"Shuffling dataset...\")\n",
        "        dataset = dataset.shuffle(buffer_size=len(clear_paths))\n",
        "\n",
        "    print(\"Batching dataset...\")\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    print(\"Dataset created and ready for use.\")\n",
        "    return dataset\n",
        "\n",
        "# Define the pairs of directories\n",
        "# Define the pairs of directories\n",
        "dir_pairs = [\n",
        "    ('/content/drive/My Drive/diss/myproj/data_train/clear_images/strasbourg', '/content/drive/My Drive/diss/myproj/data_train/hazy_images/strasbourg'),\n",
        "    ('/content/drive/My Drive/diss/myproj/data_train/clear_images/hamburg', '/content/drive/My Drive/diss/myproj/data_train/hazy_images/hamburg'),\n",
        "    ('/content/drive/My Drive/diss/myproj/data_train/clear_images/aachen', '/content/drive/My Drive/diss/myproj/data_train/hazy_images/aachen'),\n",
        "    ('/content/drive/My Drive/diss/myproj/data_train/clear_images/hanover', '/content/drive/My Drive/diss/myproj/data_train/hazy_images/hanover')\n",
        "]\n",
        "\n",
        "\n",
        "# Create and use the TensorFlow dataset\n",
        "print(\"Starting dataset creation...\")\n",
        "dataset = create_dataset(dir_pairs)\n",
        "\n",
        "# Display some info about the dataset (optional)\n",
        "for hazy_images, clear_images in dataset.take(1):\n",
        "    print(f\"Sample batch - Hazy images shape: {hazy_images.shape}, dtype: {hazy_images.dtype}\")\n",
        "    print(f\"Sample batch - Clear images shape: {clear_images.shape}, dtype: {clear_images.dtype}\")\n",
        "\n",
        "#####################\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Clear any previous session\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Set the mixed precision policy\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "set_global_policy('float32')\n",
        "\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from dehaze import model, build_unet, my_loss, psnr_metric, ssim_metric  # Adjust import according to your file structure\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "#from dataset import hazy_images, clear_images_matched  # Assuming these are loaded and prepared as shown\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.image import psnr, ssim\n",
        "\n",
        "# Assuming `dataset` is your complete dataset returned from `create_dataset`\n",
        "# First, let's count the number of items in the dataset\n",
        "dataset_size = len(dataset)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "full_dataset = dataset.shuffle(buffer_size=dataset_size)\n",
        "train_dataset = full_dataset.take(train_size)\n",
        "val_dataset = full_dataset.skip(train_size)\n",
        "\n",
        "# Continue with your model definition and training as before\n",
        "# Ensure you use `train_dataset` and `val_dataset` for training and validation, respectively.\n",
        "\n",
        "\n",
        "\n",
        "def create_dataset_from_paths(hazy_paths, clear_paths, image_size=(256, 256), batch_size=32, shuffle=True):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((hazy_paths, clear_paths))\n",
        "    dataset = dataset.map(lambda x, y: process_path(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(hazy_paths))\n",
        "\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# Load and prepare your data\n",
        "# Ensure datasets are TensorFlow Dataset objects correctly batched\n",
        "def prepare_tf_dataset(hazy_images, clear_images, batch_size=6):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((hazy_images, clear_images))\n",
        "    dataset = dataset.shuffle(buffer_size=len(hazy_images)).batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_size = int(0.8 * len(hazy_images))\n",
        "train_hazy, train_clear = hazy_images[:train_size], clear_images[:train_size]\n",
        "val_hazy, val_clear = hazy_images[train_size:], clear_images[train_size:]\n",
        "\n",
        "# Prepare TensorFlow datasets\n",
        "train_dataset = prepare_tf_dataset(train_hazy, train_clear, batch_size=6)\n",
        "val_dataset = prepare_tf_dataset(val_hazy, val_clear, batch_size=6)\n",
        "\n",
        "\n",
        "# Assume load_datasets returns properly prepared and normalized TensorFlow Dataset objects\n",
        "#train_dataset, val_dataset = load_datasets()\n",
        "\n",
        "# Build the model\n",
        "model = build_unet((256, 256, 3))\n",
        "\n",
        "# Define a learning rate schedule\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-4,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9,\n",
        "    staircase=True)\n",
        "\n",
        "\n",
        "# Compile the model using Mean Squared Error (MSE) as the loss function\n",
        "model.compile(optimizer=Adam(learning_rate=lr_schedule),\n",
        "              loss=custom_loss,  # Using built-in MSE loss\n",
        "              metrics=[psnr_metric, ssim_metric])\n",
        "\n",
        "\n",
        "\n",
        "# Custom callback for epoch printing\n",
        "class TrainingPrint(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        print(f\"Starting Epoch {epoch+1}\")\n",
        "\n",
        "\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,  # Number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,\n",
        "    mode='min')\n",
        "\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs = 30,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=[ early_stopping_callback, TrainingPrint()])\n",
        "\n",
        "\n",
        "# Save the final model\n",
        "model.save('/content/drive/My Drive/diss/myproj/results/3_6VGG19LossMSEModFogTanh.keras')\n",
        "\n",
        "# Evaluate the model on the validation dataset\n",
        "val_loss, val_psnr, val_ssim = model.evaluate(val_dataset)\n",
        "print(f\"Validation Loss: {val_loss}, Validation PSNR: {val_psnr}, Validation SSIM: {val_ssim}\")\n",
        "\n",
        "# Plotting the training history (loss, PSNR, SSIM)\n",
        "# You can use the plotting code you've provided to visualize the training and validation metrics over epochs.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
